{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_tweets.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMSViQyWH+hwkAlVRCVT4h8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anasben7/deepTweets/blob/main/deep_tweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlQLntbGdeB4",
        "outputId": "a32e8c68-d7f5-4e8f-e99d-8c0dc74789c5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/MyDrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lm3GDlU4XD0m"
      },
      "source": [
        "# Using Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0pInR9DdvX6"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxCe0ahxiDbO",
        "outputId": "bd19038e-ff93-461d-96a6-8ecf6853dcd9"
      },
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "stem = WordNetLemmatizer()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "e6os2IeWhwr4",
        "outputId": "ebb3526f-b554-42f1-ee75-abfa0943ac3f"
      },
      "source": [
        "# read the train and test file\n",
        "df = pd.read_csv(\"/content/MyDrive/MyDrive/Colab Notebooks/data/deep_tweets/train.csv\")\n",
        "df_test_original = pd.read_csv(\"/content/MyDrive/MyDrive/Colab Notebooks/data/deep_tweets/test.csv\")  \n",
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TweetId</th>\n",
              "      <th>Label</th>\n",
              "      <th>TweetText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>304271250237304833</td>\n",
              "      <td>Politics</td>\n",
              "      <td>'#SecKerry: The value of the @StateDept and @U...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>304834304222064640</td>\n",
              "      <td>Politics</td>\n",
              "      <td>'@rraina1481 I fear so'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>303568995880144898</td>\n",
              "      <td>Sports</td>\n",
              "      <td>'Watch video highlights of the #wwc13 final be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>304366580664528896</td>\n",
              "      <td>Sports</td>\n",
              "      <td>'RT @chelscanlan: At Nitro Circus at #AlbertPa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>296770931098009601</td>\n",
              "      <td>Sports</td>\n",
              "      <td>'@cricketfox Always a good thing. Thanks for t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              TweetId  ...                                          TweetText\n",
              "0  304271250237304833  ...  '#SecKerry: The value of the @StateDept and @U...\n",
              "1  304834304222064640  ...                            '@rraina1481 I fear so'\n",
              "2  303568995880144898  ...  'Watch video highlights of the #wwc13 final be...\n",
              "3  304366580664528896  ...  'RT @chelscanlan: At Nitro Circus at #AlbertPa...\n",
              "4  296770931098009601  ...  '@cricketfox Always a good thing. Thanks for t...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "BBS1ZGKpiTrZ",
        "outputId": "5b67bc36-917e-4f79-bdc1-3c2df2539344"
      },
      "source": [
        "# visualizing the two labels by the number of tweets\n",
        "import seaborn as sns\n",
        "sns.countplot(x='Label', data=df)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1804708940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uinNsc9jKCR3"
      },
      "source": [
        "df.drop('TweetId',axis = 1,inplace = True)\n",
        "# we will use this later on to create the submission.csv file\n",
        "test_TweetId = df_test_original['TweetId'].values"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKupsqbJjYc8"
      },
      "source": [
        "#Encoding the labels : 1 for Sports and 0 for Politics\n",
        "y = df[\"Label\"]\n",
        "y = np.array(list(map(lambda x: 1 if x==\"Sports\" else 0, y)))\n",
        "x = df[\"TweetText\"].to_list()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5comBsgvjrqh"
      },
      "source": [
        "#Removing stop words with NLTK, the punctuation marks and terms like RT and via\n",
        "punctuation = list(string.punctuation)\n",
        "stop = stopwords.words('english') + punctuation + ['rt', 'via']\n",
        "\n",
        "#Function to clean our Data\n",
        "def clean_data(x):\n",
        "    texts = []\n",
        "    for sen in range(0, len(x)):\n",
        "        text = re.sub(r'\\W', ' ', str(x[sen]))\n",
        "        text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
        "        text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
        "        text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', text)  \n",
        "        text = re.sub(r\"\\d\",\"\",text)\n",
        "        text = re.sub(r\"\\n\",\"\",text)\n",
        "        text = re.sub(r'[^\\w\\s]','',text)       \n",
        "        text = re.sub(r'[^\\x00-\\x7f]',r' ',text)\n",
        "        text = text.lower()\n",
        "        text = text.split()\n",
        "        text = [stem.lemmatize(word) for word in text]\n",
        "        text = ' '.join([w for w in text if w not in stop])\n",
        "        texts.append(text)\n",
        "    return texts"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rfw4v82xoCOm"
      },
      "source": [
        "x = clean_data(x)\n",
        "df_test = df_test_original.copy()\n",
        "x_test = clean_data(df_test['TweetText'].to_list())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfEbu9awoHyB"
      },
      "source": [
        "vectorizer = CountVectorizer(max_features=1067, min_df=5, \n",
        "                             max_df=0.7, stop_words=stopwords.words('english'))\n",
        "x = vectorizer.fit_transform(x).toarray()\n",
        "tfidfconverter = TfidfTransformer()\n",
        "x = tfidfconverter.fit_transform(x).toarray()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGn3MHKEpppK"
      },
      "source": [
        "# Divide dataset into train and test data\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FP39PIjg-cfN"
      },
      "source": [
        "class LogisticRegression(object):\n",
        "  \"\"\"Logistic Regression classifier.\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_iter : int, default 1000\n",
        "        number of iterations the gradient descent should process\n",
        "    eta : int, default 0.1\n",
        "        the learning rate.\n",
        "        High learning rate: might overshoot the minimum\n",
        "        Low learning rate: gradient descent could take too long (does not reach minimum within n_iter)\n",
        "    Attributes\n",
        "    ----------\n",
        "    weights : array, shape(n_features, )\n",
        "        Coefficients for the hypothesis. The weights will be 'fitted' during the gradient descent\n",
        "    costs_per_iter : array, shape(n_iter, )\n",
        "        Contains the sum of costs for every iteration\n",
        "    \"\"\"\n",
        "  def __init__(self, eta=0.1, n_iter=1000):  \n",
        "      self.eta = eta\n",
        "      self.n_iter = n_iter\n",
        "      self.weights = []\n",
        "      self.costs_per_iter = []\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    \"\"\"Fit training data.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : {array-like}, shape = [n_samples, n_features]\n",
        "            Training vectors, where n_samples is the number of samples and\n",
        "            n_features is the number of features.\n",
        "        y : array-like, shape = [n_samples]\n",
        "            Target values.\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "        \"\"\"\n",
        "    X = self.add_column_with_ones(X)  \n",
        "    self.weights = np.zeros(X.shape[1])\n",
        "    for _ in range(self.n_iter):\n",
        "        # Gradient descent\n",
        "        self.weights -= self.eta * np.dot(X.T, self.costs(X, y)) / len(y)\n",
        "        # Append current costs (just for visualization purposes)\n",
        "        self.costs_per_iter.append(np.absolute(self.costs(X, y)).sum())\n",
        "            \n",
        "  def costs(self, X, y):\n",
        "      return self.hypothesis(X) - y\n",
        "\n",
        "  def hypothesis(self, X):\n",
        "      return 1 / (1 + np.exp(-np.dot(X, self.weights)))\n",
        "\n",
        "  def predict(self, X):\n",
        "      \"\"\"\n",
        "        Predict the target value(s)\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : numpy array, shape(m_samples, n_features)\n",
        "            Data to use for prediction\n",
        "        Returns\n",
        "        -------\n",
        "        prediction : numpy array, shape(m_samples, )\n",
        "            Prediction for every sample in X\n",
        "        \"\"\"\n",
        "    \n",
        "      X = self.add_column_with_ones(X)\n",
        "      return np.where(self.hypothesis(X) >= 0.5, 1, 0)\n",
        "\n",
        "  def add_column_with_ones(self, X):\n",
        "      # Add one column with ones (for weight_0, the 'bias')\n",
        "      # Otherwise you have to calculate weight[0] and weight[1:] separately\n",
        "      return np.concatenate([np.ones((len(X), 1)), X], axis=1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjmdK7meLj7v"
      },
      "source": [
        "# Instantiate a new LogisticRegression and call its fit-method with the train data\n",
        "lr = LogisticRegression()\n",
        "lr.fit(np.array(x_train), np.array(y_train))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_PSz5NQq0I7",
        "outputId": "1ddb86f8-d12d-4984-a82d-6d627e1b1dfb"
      },
      "source": [
        "# Predict the result with the validating data only\n",
        "y_pred = lr.predict(x_valid)\n",
        "print(\"Accuracy Score\", accuracy_score(y_valid, y_pred))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score 0.8996168582375479\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWvWtpOIvOtw"
      },
      "source": [
        "x_test = vectorizer.fit_transform(x_test).toarray()\n",
        "x_test = tfidfconverter.fit_transform(x_test).toarray()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LKL9dmAv4I4"
      },
      "source": [
        "predictions = lr.predict(x_test)\n",
        "predictions = np.array(list(map(lambda x: \"Sports\" if x==1 else \"Politics\", predictions)))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "p6QhEAph5dmP",
        "outputId": "5ad8441b-e5c7-4ae0-9e4b-0c66b097ac8d"
      },
      "source": [
        "submission = {\n",
        "    'TweetId': test_TweetId,\n",
        "    'Label': predictions\n",
        "}\n",
        "results = pd.DataFrame(submission)\n",
        "results.head(10)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TweetId</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>306486520121012224</td>\n",
              "      <td>Sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>286353402605228032</td>\n",
              "      <td>Sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>289531046037438464</td>\n",
              "      <td>Politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>306451661403062273</td>\n",
              "      <td>Sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>297941800658812928</td>\n",
              "      <td>Sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>305722428531802112</td>\n",
              "      <td>Politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>304713516256997377</td>\n",
              "      <td>Sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>234999630725783553</td>\n",
              "      <td>Sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>303712268372283392</td>\n",
              "      <td>Sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>304215754130194432</td>\n",
              "      <td>Sports</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              TweetId     Label\n",
              "0  306486520121012224    Sports\n",
              "1  286353402605228032    Sports\n",
              "2  289531046037438464  Politics\n",
              "3  306451661403062273    Sports\n",
              "4  297941800658812928    Sports\n",
              "5  305722428531802112  Politics\n",
              "6  304713516256997377    Sports\n",
              "7  234999630725783553    Sports\n",
              "8  303712268372283392    Sports\n",
              "9  304215754130194432    Sports"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQdfhjg9m954"
      },
      "source": [
        "results.to_csv(\"submission.csv\",index=False)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNYLJY-gXKrg"
      },
      "source": [
        "# Using Deep Learning CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_6Q59kpXRkT"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as st\n",
        "import seaborn as sns\n",
        "import pandas_profiling\n",
        "import requests\n",
        "from sklearn.datasets import load_files\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P49DE3X2ZaXL",
        "outputId": "d926dfdb-c245-4f13-ff5e-80b80cd3cff1"
      },
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "stem = WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "HmQC1AbIXgXB",
        "outputId": "c0bff981-b16d-49d3-e78d-b4945e72c57c"
      },
      "source": [
        "df = pd.read_csv(\"/content/MyDrive/MyDrive/Colab Notebooks/data/deep_tweets/train.csv\")\n",
        "df_test_original = pd.read_csv(\"/content/MyDrive/MyDrive/Colab Notebooks/data/deep_tweets/test.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TweetId</th>\n",
              "      <th>Label</th>\n",
              "      <th>TweetText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>304271250237304833</td>\n",
              "      <td>Politics</td>\n",
              "      <td>'#SecKerry: The value of the @StateDept and @U...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>304834304222064640</td>\n",
              "      <td>Politics</td>\n",
              "      <td>'@rraina1481 I fear so'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>303568995880144898</td>\n",
              "      <td>Sports</td>\n",
              "      <td>'Watch video highlights of the #wwc13 final be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>304366580664528896</td>\n",
              "      <td>Sports</td>\n",
              "      <td>'RT @chelscanlan: At Nitro Circus at #AlbertPa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>296770931098009601</td>\n",
              "      <td>Sports</td>\n",
              "      <td>'@cricketfox Always a good thing. Thanks for t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              TweetId  ...                                          TweetText\n",
              "0  304271250237304833  ...  '#SecKerry: The value of the @StateDept and @U...\n",
              "1  304834304222064640  ...                            '@rraina1481 I fear so'\n",
              "2  303568995880144898  ...  'Watch video highlights of the #wwc13 final be...\n",
              "3  304366580664528896  ...  'RT @chelscanlan: At Nitro Circus at #AlbertPa...\n",
              "4  296770931098009601  ...  '@cricketfox Always a good thing. Thanks for t...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCHMwCm7X8Sr",
        "outputId": "0a1187fe-4427-465e-8c17-7d53cb28ccc3"
      },
      "source": [
        "# visualizing the two labels by the number of tweets\n",
        "import seaborn as sns\n",
        "sns.countplot(x='Label', data=df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6e1a6672b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQOaWJAflLR4"
      },
      "source": [
        "df.drop('TweetId',axis = 1,inplace = True)\n",
        "# we will use this later on to create the submission.csv file\n",
        "test_TweetId = df_test_original['TweetId'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6OJn-CYoCqJ"
      },
      "source": [
        "#Encoding the labels : 1 for Sports and 0 for Politics\n",
        "y_train = df[\"Label\"]\n",
        "x = df[\"TweetText\"].to_list()\n",
        "y_train = np.array(list(map(lambda x: 1 if x==\"Sports\" else 0, y_train)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gogGS6ZTZDgD"
      },
      "source": [
        "#Removing stop words with NLTK, the punctuation marks and terms like RT and via\n",
        "punctuation = list(string.punctuation)\n",
        "stop = stopwords.words('english') + punctuation + ['rt', 'via']\n",
        "\n",
        "#Function to clean our Data\n",
        "def clean_data(x):\n",
        "    texts = []\n",
        "    for sen in range(0, len(x)):\n",
        "        text = re.sub(r'\\W', ' ', str(x[sen]))\n",
        "        text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
        "        text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
        "        text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', text)  \n",
        "        text = re.sub(r\"\\d\",\"\",text)\n",
        "        text = re.sub(r\"\\n\",\"\",text)\n",
        "        text = re.sub(r'[^\\w\\s]','',text)       \n",
        "        text = re.sub(r'[^\\x00-\\x7f]',r' ',text)\n",
        "        text = text.lower()\n",
        "        text = text.split()\n",
        "        text = [stem.lemmatize(word) for word in text]\n",
        "        text = ' '.join([w for w in text if w not in stop])\n",
        "        texts.append(text)\n",
        "    return texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5tm3CY_mFc1"
      },
      "source": [
        "x_train = clean_data(x)\n",
        "df_test = df_test_original.copy()\n",
        "x_test = clean_data(df_test['TweetText'].to_list())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFxsr4TNqC9G"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import tensorflow as tf\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "x_train,x_valid,y_train,y_valid = train_test_split(x_train,y_train,test_size=0.2)\n",
        "x_train = np.array(tokenizer.texts_to_sequences(x_train))\n",
        "x_valid = np.array(tokenizer.texts_to_sequences(x_valid))\n",
        "maxlen = 500\n",
        "x_train = pad_sequences(x_train,padding=\"post\",maxlen=maxlen)\n",
        "x_valid = pad_sequences(x_valid,padding=\"post\",maxlen=maxlen)\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_valid = le.fit_transform(y_valid)\n",
        "\n",
        "y_train = np.asarray(tf.keras.utils.to_categorical(y_train))\n",
        "y_valid = np.asarray(tf.keras.utils.to_categorical(y_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbCoJqsVqgFf"
      },
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
        "valid_ds = tf.data.Dataset.from_tensor_slices((x_valid,y_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCukGFhAqnOm",
        "outputId": "2ad4da48-5d18-4460-c432-9d3698a96326"
      },
      "source": [
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import losses\n",
        "max_features = 20000\n",
        "embedding_dim = 64\n",
        "sequence_length = 40\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(max_features+1,embedding_dim,input_length=sequence_length,embeddings_regularizer=regularizers.l2(0.0005) ))\n",
        "model.add(tf.keras.layers.Conv1D(128,3,activation='relu',kernel_regularizer=regularizers.l2(0.0005),bias_regularizer=regularizers.l2(0.0005)))\n",
        "model.add(tf.keras.layers.Conv1D(150,2,activation='relu',kernel_regularizer=regularizers.l2(0.0005),bias_regularizer=regularizers.l2(0.0005)))\n",
        "model.add(tf.keras.layers.GlobalMaxPool1D())\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(2,activation='sigmoid',kernel_regularizer=regularizers.l2(0.01),bias_regularizer=regularizers.l1(0.01)))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 40, 64)            1280064   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 38, 128)           24704     \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 37, 150)           38550     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 302       \n",
            "=================================================================\n",
            "Total params: 1,343,620\n",
            "Trainable params: 1,343,620\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNsfUVi4qsgQ"
      },
      "source": [
        "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              optimizer='adam',\n",
        "              metrics=['CategoricalAccuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyqgD4okqxoS",
        "outputId": "5b245f35-08ae-4413-bc0d-516f8bb85fb5"
      },
      "source": [
        "history = model.fit(train_ds.shuffle(2000).batch(128),\n",
        "                    epochs=25,\n",
        "                    validation_data=valid_ds.batch(128),\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 40) for input Tensor(\"embedding_input:0\", shape=(None, 40), dtype=float32), but it was called on an input with incompatible shape (None, 500).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 40) for input Tensor(\"embedding_input:0\", shape=(None, 40), dtype=float32), but it was called on an input with incompatible shape (None, 500).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "41/41 [==============================] - ETA: 0s - loss: 0.9777 - categorical_accuracy: 0.6050WARNING:tensorflow:Model was constructed with shape (None, 40) for input Tensor(\"embedding_input:0\", shape=(None, 40), dtype=float32), but it was called on an input with incompatible shape (None, 500).\n",
            "41/41 [==============================] - 1s 35ms/step - loss: 0.9777 - categorical_accuracy: 0.6050 - val_loss: 0.7615 - val_categorical_accuracy: 0.6628\n",
            "Epoch 2/25\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.6608 - categorical_accuracy: 0.7784 - val_loss: 0.5155 - val_categorical_accuracy: 0.8950\n",
            "Epoch 3/25\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.4749 - categorical_accuracy: 0.9377 - val_loss: 0.4726 - val_categorical_accuracy: 0.9333\n",
            "Epoch 4/25\n",
            "41/41 [==============================] - 1s 33ms/step - loss: 0.4370 - categorical_accuracy: 0.9716 - val_loss: 0.4621 - val_categorical_accuracy: 0.9418\n",
            "Epoch 5/25\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.4237 - categorical_accuracy: 0.9824 - val_loss: 0.4599 - val_categorical_accuracy: 0.9333\n",
            "Epoch 6/25\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.4171 - categorical_accuracy: 0.9866 - val_loss: 0.4563 - val_categorical_accuracy: 0.9333\n",
            "Epoch 7/25\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 0.4143 - categorical_accuracy: 0.9891 - val_loss: 0.4575 - val_categorical_accuracy: 0.9395\n",
            "Epoch 8/25\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.4113 - categorical_accuracy: 0.9918 - val_loss: 0.4566 - val_categorical_accuracy: 0.9341\n",
            "Epoch 9/25\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.4099 - categorical_accuracy: 0.9920 - val_loss: 0.4567 - val_categorical_accuracy: 0.9356\n",
            "Epoch 10/25\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.4085 - categorical_accuracy: 0.9923 - val_loss: 0.4549 - val_categorical_accuracy: 0.9402\n",
            "Epoch 11/25\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.4084 - categorical_accuracy: 0.9929 - val_loss: 0.4545 - val_categorical_accuracy: 0.9372\n",
            "Epoch 12/25\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 0.4080 - categorical_accuracy: 0.9916 - val_loss: 0.4535 - val_categorical_accuracy: 0.9379\n",
            "Epoch 13/25\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.4080 - categorical_accuracy: 0.9923 - val_loss: 0.4528 - val_categorical_accuracy: 0.9425\n",
            "Epoch 14/25\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.4077 - categorical_accuracy: 0.9931 - val_loss: 0.4532 - val_categorical_accuracy: 0.9387\n",
            "Epoch 15/25\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.4073 - categorical_accuracy: 0.9933 - val_loss: 0.4511 - val_categorical_accuracy: 0.9395\n",
            "Epoch 16/25\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 0.4070 - categorical_accuracy: 0.9929 - val_loss: 0.4525 - val_categorical_accuracy: 0.9364\n",
            "Epoch 17/25\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.4067 - categorical_accuracy: 0.9939 - val_loss: 0.4511 - val_categorical_accuracy: 0.9433\n",
            "Epoch 18/25\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 0.4062 - categorical_accuracy: 0.9939 - val_loss: 0.4526 - val_categorical_accuracy: 0.9418\n",
            "Epoch 19/25\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.4063 - categorical_accuracy: 0.9939 - val_loss: 0.4505 - val_categorical_accuracy: 0.9456\n",
            "Epoch 20/25\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.4066 - categorical_accuracy: 0.9931 - val_loss: 0.4501 - val_categorical_accuracy: 0.9448\n",
            "Epoch 21/25\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.4069 - categorical_accuracy: 0.9943 - val_loss: 0.4555 - val_categorical_accuracy: 0.9349\n",
            "Epoch 22/25\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.4065 - categorical_accuracy: 0.9941 - val_loss: 0.4521 - val_categorical_accuracy: 0.9341\n",
            "Epoch 23/25\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.4054 - categorical_accuracy: 0.9935 - val_loss: 0.4508 - val_categorical_accuracy: 0.9441\n",
            "Epoch 24/25\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 0.4063 - categorical_accuracy: 0.9929 - val_loss: 0.4516 - val_categorical_accuracy: 0.9364\n",
            "Epoch 25/25\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.4069 - categorical_accuracy: 0.9931 - val_loss: 0.4519 - val_categorical_accuracy: 0.9410\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lD9tV7tRq5vp"
      },
      "source": [
        "x_test = np.array(tokenizer.texts_to_sequences(df_test['TweetText'].to_list()))\n",
        "x_test = pad_sequences(x_test,padding='post',maxlen=40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKx4mwtXr1PW"
      },
      "source": [
        "predictions = model.predict(x_test)\n",
        "predict_results = predictions.argmax(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJa_EJQyr3cO"
      },
      "source": [
        "predict_results = np.array(list(map(lambda x: \"Sports\" if x==1 else \"Politics\", predict_results)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yzn7H7jkt2wc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "bae973e4-d591-451e-c211-2db849536561"
      },
      "source": [
        "submission = {\n",
        "    'TweetId': test_TweetId,\n",
        "    'Label': predict_results\n",
        "}\n",
        "results = pd.DataFrame(submission)\n",
        "results.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TweetId</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>306486520121012224</td>\n",
              "      <td>Politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>286353402605228032</td>\n",
              "      <td>Sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>289531046037438464</td>\n",
              "      <td>Sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>306451661403062273</td>\n",
              "      <td>Politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>297941800658812928</td>\n",
              "      <td>Sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>305722428531802112</td>\n",
              "      <td>Sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>304713516256997377</td>\n",
              "      <td>Sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>234999630725783553</td>\n",
              "      <td>Sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>303712268372283392</td>\n",
              "      <td>Sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>304215754130194432</td>\n",
              "      <td>Sports</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              TweetId     Label\n",
              "0  306486520121012224  Politics\n",
              "1  286353402605228032    Sports\n",
              "2  289531046037438464    Sports\n",
              "3  306451661403062273  Politics\n",
              "4  297941800658812928    Sports\n",
              "5  305722428531802112    Sports\n",
              "6  304713516256997377    Sports\n",
              "7  234999630725783553    Sports\n",
              "8  303712268372283392    Sports\n",
              "9  304215754130194432    Sports"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjwnFF-pD0an"
      },
      "source": [
        "results.to_csv(\"submission.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}